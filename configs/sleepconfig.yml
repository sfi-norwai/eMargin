# Predict command
## COMMAND: [ python, predict.py ]
# Train command

SAVE_INTERVAL: 50
VALID_INTERVAL: 5
PATIENCE: 5
TRAIN_COMMAND: [ python, train.py ]
LOO_CV_COMMAND: [python, loo_cross_validation.py]

CLASSES:
  - { label: 1,  name: 'walking',                             }
  - { label: 2,  name: 'running',                             }
  - { label: 3,  name: 'shuffling',                 }
  - { label: 4,  name: 'stairs (ascending)',        }
  - { label: 5,  name: 'stairs (descending)',       }
  - { label: 6,  name: 'standing',                            }
  - { label: 7,  name: 'sitting',                             }
  - { label: 8,  name: 'lying',                               }
  - { label: 13, name: 'cycling (sit)',                       }
  - { label: 14, name: 'cycling (stand)',           }
  - { label: 130, name: 'cycling (sit, inactive)',  }
  - { label: 140, name: 'cycling (stand, inactive)',}

# --- Information about data
# Path to training dataset 
class_count: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000}
class_count_semi: [0.01, 0.05, 0.1]

class_dict: {0: "W", 1: "N1", 2: "N2", 3: "N3", 4: "REM"}
# Amount of training data used for validation (between 0 and 1)
VALID_SPLIT: 0.2
display_batch: 12000
# Randomly selected test subjects (Not used during LOSO!)
TEST_SUBJECTS: [S027.csv,S023.csv,S008.csv,S019.csv,S006.csv,S024.csv, S010.csv,  S014.csv,  S017.csv,  S020.csv]
SEED: 42

NUM_WORKERS: 4  # Num of workers for data loading
NUM_GPUS: [0]  # How many/which GPUs to use
WANDB: False

seeds: [42]

baselines: [vanilla_cl, double_cl, margin_cl, ts2vec, infoTS, triplet, tnc, cpc, monoselfPAB, reconstruction]

output_dir: output/sleepeeg/



DATASET: SLEEPEEG
DATASET_ARGS:
  #STFT FOR SLEEPEEG
  class_to_exclude: [3]
  n_fft: [178]
  hop_length: [178]
  win_length: [178]
  seq_length: [200]
  num_labels: [5]

# -- Model 
# Which classifier to use 
ALGORITHM: DownstreamMLP
# Arguments for classifier
# (all given as lists in case to perform a GridSearch)
ALGORITHM_ARGS:
  epochs: [100]
  iterations: [600]
  linear_epochs: [10]
  margin: [5]
  feature_dim: [90]
  out_features: [320]
  temperature: [0.1]
  mask_fraction: [0.3]
  margin_thresh: [0.4]
  mse_lambda: [0.4]
  batch_size: [8]
  tnc_window: [20]
  sequence_sample: [200]

  

  # MARGIN_LOSS, LS_MARGIN_LOSS, LS_HATCL_LOSS, HATCL_LOSS
  loss: [LS_HATCL_LOSS]
  mloss: [LS_MARGIN_LOSS]
  optimizer: [AdamW]
  weight_decay: [0.0]
#   output_activation: [softmax]
#   metrics: [[F1Score,Accuracy,Precision,Recall]]  # Which metrics to log
  lr: [1e-3]
  lr_scheduler: [ExponentialTFDecay]
  number_subject: [10]
  number_sample: [1]
  total_subjects: [30000]
  # lr_scheduler: [LinearWUSchedule]
  # Architecture params

STORE_CMATS: True  # Store test cmats on disk
SKIP_FINISHED_ARGS: False

# Metric which defines the best model
EVAL_METRIC: average_f1score
